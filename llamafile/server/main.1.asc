[4mLLAMAFILER[24m(1)               General Commands Manual              [4mLLAMAFILER[24m(1)

[1mNAME[0m
       llamafiler ‚Äî fast reliable embedding server

[1mSYNOPSIS[0m
       [1mllamafiler -m [4m[22mmodel.gguf[24m [flags...]

[1mDESCRIPTION[0m
       [1mllamafiler [22mis a brand new HTTP server for Large Language Models (LLMs).
       To  date, its development has been focused on doing fewer things really
       well, and right now that's serving embeddings. It offers you  3.4x  the
       performance,  stronger security, client request prioritization, request
       preemption, as well as request isolation  that  helps  ensure  software
       bugs won't cause the whole server to crash.

[1mOPTIONS[0m
       The following options are available:

       [1m--version[0m
               Print version and exit.

       [1m-h[22m, [1m--help[0m
               Show help message and exit.

       [1m-m [4m[22mFNAME[24m, [1m--model [4m[22mFNAME[0m
               Path  of  GGUF  model weights. Each server process is currently
               limited to serving only one model. If you need to host multiple
               models, then it's recommended that you run  multiple  instances
               of llamafiler behind a reverse proxy such as NGINX or Redbean.

       [1m-l [4m[22mHOSTPORT[24m, [1m--listen [4m[22mHOSTPORT[0m
               Specifies the local [HOST:]PORT on which the HTTP server should
               listen.  By default this is 0.0.0.0:8080 which means llamafiler
               will  bind to port 8080 on every locally available IPv4 network
               interface. This option may currently only be specified once.

       [1m--url-prefix [4m[22mURLPREFIX[0m
               Specifies a URL prefix  (subdirectory)  under  which  the  HTTP
               server  will  make  the API accessible, e.g. /lamafiler. Useful
               when running llamafiler behind a reverse proxy such as NGINX or
               Redbean. By default, this is set to / (root).

       [1m-w [4m[22mN[24m, [1m--workers [4m[22mN[0m
               Number of HTTP client handling threads.

       [1m--trust [4m[22mCIDR[0m
               Adds a network to the trusted network list.  This  argument  is
               specified  in  the  form IPV4/MASKBITS, e.g. 192.168.0.0/24. By
               default, all clients are untrusted, which means they're subject
               to token bucket throttling, and additional security precautions
               that may cause request handling to go slightly  slower.  There‚Äê
               fore  this  flag  is important to use if you want to accurately
               benchmark llamafiler, since the server will otherwise  see  the
               benchmark as a DDOS and deprioritize its traffic accordingly.

       [1m--ip-header [4m[22mSTR[0m
               If  this flag is passed a value, e.g. X-Forwarded-For, then any
               trusted may send this header to your llamafile server to let it
               know what the true effective client IPv4 address  actually  is.
               After  this happens the default security restrictions, e.g. to‚Äê
               ken bucket, will be measured and applied against that IPv4  ad‚Äê
               dress and its adjacent networks.

       [1m--token-rate [4m[22mN[0m
               Specifies  how many times per second a token is dropped in each
               bucket.  This setting is used to define  a  limitation  on  how
               many  TCP connects and HTTP messages each chunk of the IPv4 ad‚Äê
               dress space is permitted to send to llamafiler over a sustained
               period of time. The default token rate is 1, which means  that,
               on  a long enough timeline, a class-C network will be depriori‚Äê
               tized if it sends more than one request  per  second.  No  real
               penalty  actually  applies  though until the server runs out of
               resources, e.g. HTTP request workers.

       [1m--token-burst [4m[22mN[0m
               Specifies how many HTTP requests and TCP connects a given slice
               of the IPv4 address space is permitted to send within  a  short
               period  of  time, before token bucket restrictions kick in, and
               cause the client to be deprioritized. By default, this value is
               set to 100. It may be tuned to any value between 1 and 127  in‚Äê
               clusive.

       [1m--token-cidr [4m[22mN[0m
               Specifies  IPv4 address space granularity of token bucket algo‚Äê
               rithm, in network bits. By default, this value  is  set  to  24
               which  means individual IPv4 addresses are viewed as being rep‚Äê
               resentative members of a class-C network, or  in  other  words,
               each  group of 256 IPv4 addresses is lumped together. If one IP
               in the group does something bad, then bad things happen to  all
               the  other  IPv4  addresses in that granule. This number may be
               set to any integer between 3 and  32  inclusive.  Specifying  a
               higher number will trade away system memory to increase network
               specificity.   For example, using 32 means that 4 billion indi‚Äê
               vidual token buckets will be created. By default, a  background
               thread  drops  one  token  in each bucket every second, so that
               could potentially be a lot of busy work. A value of three means
               that everyone on the Internet who talks  to  your  server  will
               have to fight over only eight token buckets in total.

       [1m--unsecure[0m
               Disables  sandboxing.  By  default, llamafiler puts itself in a
               SECCOMP BPF sandbox, so that even if your server gets hacked in
               the worst possible way (some  kind  of  C++  memory  bug)  then
               there's very little damage an attacker will be able to do. This
               works by restricting system calls using Cosmopolitan Libc's im‚Äê
               plementation  of  pledge() which is currently only supported on
               Linux (other OSes will simply be  unsecured  by  default).  The
               pledge  security  policy that's used by default is "stdio anet"
               which means that only relatively  harmless  system  calls  like
               read(),  write(),  and accept() are allowed once the server has
               finished initializing. It's not possible for remotely  executed
               code  to  do  things like launch subprocesses, read or write to
               the filesystem, or initiate a new connection to a server.

       [1m-k [4m[22mN[24m, [1m--keepalive [4m[22mN[0m
               Specifies the TCP keepalive interval in seconds. This value  is
               passed  along to both TCP_KEEPIDLE and TCP_KEEPINTVL if they're
               supported by the  host  operating  system.  If  this  value  is
               greater  than  0, then the the SO_KEEPALIVE and TCP_NODELAY op‚Äê
               tions are enabled on network sockets, if supported by the  host
               operating system. The default keepalive is 5.

       [1m--http-obuf-size [4m[22mN[0m
               Size of HTTP output buffer size, in bytes. Default is 1048576.

       [1m--http-ibuf-size [4m[22mN[0m
               Size of HTTP input buffer size, in bytes. Default is 1048576.

[1mEXAMPLE[0m
       Here's an example of how you might start this server:

             [1mllamafiler -m all-MiniLM-L6-v2.F32.gguf[0m

       Here's how to send a tokenization request:

             [1mcurl -v http://127.0.0.1:8080/tokenize?prompt=hello+world[0m

       Here's how to send a embedding request:

             [1mcurl -v http://127.0.0.1:8080/embedding?content=hello+world[0m

[1mDOCUMENTATION[0m
       Read  our Markdown documentation for additional help and tutorials. See
       llamafile/server/doc/index.md in the source repository on GitHub.

[1mSEE ALSO[0m
       [4mllamafile[24m(1), [4mwhisperfile[24m(1)

Mozilla Ocho                    August 17, 2024                  [4mLLAMAFILER[24m(1)
